{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3d42d15",
   "metadata": {},
   "source": [
    "# # Performance Analysis: Tree Training and Cross-Validation\n",
    "# \n",
    "# This notebook analyzes the performance comparison between serial and parallel implementations for:\n",
    "# 1. Decision Tree Training\n",
    "# 2. Cross-Validation\n",
    "# \n",
    "# We'll examine performance across different tree depths, thread counts, and datasets (cancer, hmeq).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0207e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better-looking plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set figure size defaults\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3307e6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tree_benchmark_data():\n",
    "    \"\"\"Load and combine all tree benchmark data files\"\"\"\n",
    "    # Load serial data\n",
    "    serial_df = pd.read_csv('benchmark_results_serial.csv')\n",
    "    \n",
    "    # Load parallel data with different thread counts\n",
    "    parallel_dfs = []\n",
    "    for threads in [1, 2, 3, 4]:\n",
    "        df = pd.read_csv(f'benchmark_results_parallel_{threads}threads.csv')\n",
    "        df['threads'] = threads\n",
    "        parallel_dfs.append(df)\n",
    "    \n",
    "    # Combine all parallel data\n",
    "    parallel_df = pd.concat(parallel_dfs, ignore_index=True)\n",
    "    \n",
    "    return serial_df, parallel_df\n",
    "\n",
    "def load_cv_benchmark_data():\n",
    "    \"\"\"Load and combine all CV benchmark data files\"\"\"\n",
    "    # Load serial CV data\n",
    "    serial_cv_df = pd.read_csv('cv_results_serial.csv')\n",
    "    \n",
    "    # Load parallel CV data with different thread counts\n",
    "    parallel_cv_dfs = []\n",
    "    for threads in [1, 2, 3, 4]:\n",
    "        df = pd.read_csv(f'cv_results_parallel_{threads}threads.csv')\n",
    "        df['threads'] = threads\n",
    "        parallel_cv_dfs.append(df)\n",
    "    \n",
    "    # Combine all parallel CV data\n",
    "    parallel_cv_df = pd.concat(parallel_cv_dfs, ignore_index=True)\n",
    "    \n",
    "    return serial_cv_df, parallel_cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee6f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data\n",
    "print(\"Loading tree benchmark data...\")\n",
    "serial_tree_df, parallel_tree_df = load_tree_benchmark_data()\n",
    "\n",
    "print(\"Loading CV benchmark data...\")\n",
    "serial_cv_df, parallel_cv_df = load_cv_benchmark_data()\n",
    "\n",
    "print(f\"Tree data loaded: {len(serial_tree_df)} serial rows, {len(parallel_tree_df)} parallel rows\")\n",
    "print(f\"CV data loaded: {len(serial_cv_df)} serial CV rows, {len(parallel_cv_df)} parallel CV rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88608fa4",
   "metadata": {},
   "source": [
    "## Data Overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5204db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Tree Benchmark Data Structure ===\")\n",
    "print(\"Serial tree data columns:\", serial_tree_df.columns.tolist())\n",
    "print(\"Parallel tree data columns:\", parallel_tree_df.columns.tolist())\n",
    "print(\"\\nUnique datasets:\", serial_tree_df['dataset'].unique())\n",
    "print(\"Tree depth range:\", f\"{serial_tree_df['max_depth'].min()} - {serial_tree_df['max_depth'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e0cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== CV Benchmark Data Structure ===\")\n",
    "print(\"Serial CV data columns:\", serial_cv_df.columns.tolist())\n",
    "print(\"Parallel CV data columns:\", parallel_cv_df.columns.tolist())\n",
    "print(\"\\nUnique datasets:\", serial_cv_df['dataset'].unique())\n",
    "print(\"CV depth range:\", f\"{serial_cv_df['max_depth'].min()} - {serial_cv_df['max_depth'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40302f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample data preview\n",
    "print(\"=== Sample Tree Data ===\")\n",
    "display(serial_tree_df.head(3))\n",
    "\n",
    "print(\"\\n=== Sample CV Data ===\")\n",
    "display(serial_cv_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956c5ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tree_performance():\n",
    "    \"\"\"Create tree training performance graphs\"\"\"\n",
    "    datasets = ['cancer', 'hmeq']\n",
    "    \n",
    "    # Create figure with subplots for each dataset\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    fig.suptitle('Tree Training Performance: Serial vs Parallel', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for i, dataset in enumerate(datasets):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Filter data for current dataset\n",
    "        serial_data = serial_tree_df[serial_tree_df['dataset'] == dataset]\n",
    "        \n",
    "        # Plot serial performance\n",
    "        ax.plot(serial_data['max_depth'], serial_data['train_time_ms'], \n",
    "                marker='o', linewidth=2, label='Serial Tree', color='red')\n",
    "        \n",
    "        # Plot parallel performance for different thread counts\n",
    "        colors = ['orange', 'green', 'blue', 'purple']\n",
    "        for j, threads in enumerate([1, 2, 3, 4]):\n",
    "            parallel_data = parallel_tree_df[(parallel_tree_df['dataset'] == dataset) & \n",
    "                                          (parallel_tree_df['threads'] == threads)]\n",
    "            ax.plot(parallel_data['max_depth'], parallel_data['train_time_ms'],\n",
    "                   marker='s', linewidth=2, label=f'Parallel Tree ({threads} threads)', \n",
    "                   color=colors[j], alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Tree Depth', fontsize=12)\n",
    "        ax.set_ylabel('Training Time (ms)', fontsize=12)\n",
    "        ax.set_title(f'{dataset.capitalize()} Dataset', fontsize=14, fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_yscale('log')  # Log scale for better visualization of time differences\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('tree_performance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_tree_performance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ca5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv_performance():\n",
    "    \"\"\"Create cross-validation performance graphs\"\"\"\n",
    "    datasets = ['cancer', 'hmeq']\n",
    "    \n",
    "    # Create figure with subplots for each dataset\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    fig.suptitle('Cross-Validation Performance: Serial vs Parallel', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for i, dataset in enumerate(datasets):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Filter data for current dataset\n",
    "        serial_data = serial_cv_df[serial_cv_df['dataset'] == dataset]\n",
    "        \n",
    "        # Plot serial CV performance\n",
    "        ax.plot(serial_data['max_depth'], serial_data['cv_time_ms'], \n",
    "                marker='o', linewidth=2, label='Serial CV', color='red')\n",
    "        \n",
    "        # Plot parallel CV performance for different thread counts\n",
    "        colors = ['orange', 'green', 'blue', 'purple']\n",
    "        for j, threads in enumerate([1, 2, 3, 4]):\n",
    "            parallel_data = parallel_cv_df[(parallel_cv_df['dataset'] == dataset) & \n",
    "                                         (parallel_cv_df['threads'] == threads)]\n",
    "            ax.plot(parallel_data['max_depth'], parallel_data['cv_time_ms'],\n",
    "                   marker='s', linewidth=2, label=f'Parallel CV ({threads} threads)', \n",
    "                   color=colors[j], alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Tree Depth', fontsize=12)\n",
    "        ax.set_ylabel('Cross-Validation Time (ms)', fontsize=12)\n",
    "        ax.set_title(f'{dataset.capitalize()} Dataset', fontsize=14, fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_yscale('log')  # Log scale for better visualization of time differences\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cv_performance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Execute the CV performance analysis\n",
    "plot_cv_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72944da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_speedup_analysis():\n",
    "    \"\"\"Create speedup analysis graphs\"\"\"\n",
    "    datasets = ['cancer', 'hmeq']\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Speedup Analysis: Serial vs Parallel (4 Threads)', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for i, dataset in enumerate(datasets):\n",
    "        # Tree speedup\n",
    "        ax_tree = axes[0, i]\n",
    "        serial_tree = serial_tree_df[serial_tree_df['dataset'] == dataset]\n",
    "        parallel_tree = parallel_tree_df[(parallel_tree_df['dataset'] == dataset) & \n",
    "                                      (parallel_tree_df['threads'] == 4)]\n",
    "        \n",
    "        # Calculate speedup\n",
    "        speedup_tree = serial_tree['train_time_ms'].values / parallel_tree['train_time_ms'].values\n",
    "        \n",
    "        ax_tree.plot(serial_tree['max_depth'], speedup_tree, \n",
    "                    marker='o', linewidth=2, color='blue')\n",
    "        ax_tree.axhline(y=1, color='red', linestyle='--', alpha=0.7, label='No speedup')\n",
    "        ax_tree.set_xlabel('Tree Depth')\n",
    "        ax_tree.set_ylabel('Speedup Factor')\n",
    "        ax_tree.set_title(f'Tree Training Speedup - {dataset.capitalize()}')\n",
    "        ax_tree.legend()\n",
    "        ax_tree.grid(True, alpha=0.3)\n",
    "        \n",
    "        # CV speedup\n",
    "        ax_cv = axes[1, i]\n",
    "        serial_cv = serial_cv_df[serial_cv_df['dataset'] == dataset]\n",
    "        parallel_cv = parallel_cv_df[(parallel_cv_df['dataset'] == dataset) & \n",
    "                                   (parallel_cv_df['threads'] == 4)]\n",
    "        \n",
    "        # Calculate speedup\n",
    "        speedup_cv = serial_cv['cv_time_ms'].values / parallel_cv['cv_time_ms'].values\n",
    "        \n",
    "        ax_cv.plot(serial_cv['max_depth'], speedup_cv, \n",
    "                  marker='s', linewidth=2, color='green')\n",
    "        ax_cv.axhline(y=1, color='red', linestyle='--', alpha=0.7, label='No speedup')\n",
    "        ax_cv.set_xlabel('Tree Depth')\n",
    "        ax_cv.set_ylabel('Speedup Factor')\n",
    "        ax_cv.set_title(f'Cross-Validation Speedup - {dataset.capitalize()}')\n",
    "        ax_cv.legend()\n",
    "        ax_cv.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('speedup_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Execute speedup analysis\n",
    "plot_speedup_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9674b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_thread_scaling():\n",
    "    \"\"\"Create thread scaling analysis\"\"\"\n",
    "    # Select specific depths for analysis\n",
    "    depths_to_analyze = [5, 10, 15, 20]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Thread Scaling Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    datasets = ['cancer', 'hmeq']\n",
    "    \n",
    "    for i, dataset in enumerate(datasets):\n",
    "        # Tree scaling\n",
    "        ax_tree = axes[0, i]\n",
    "        for depth in depths_to_analyze:\n",
    "            times = []\n",
    "            for threads in [1, 2, 3, 4]:\n",
    "                data = parallel_tree_df[(parallel_tree_df['dataset'] == dataset) & \n",
    "                                     (parallel_tree_df['max_depth'] == depth) & \n",
    "                                     (parallel_tree_df['threads'] == threads)]\n",
    "                if not data.empty:\n",
    "                    times.append(data['train_time_ms'].iloc[0])\n",
    "                else:\n",
    "                    times.append(None)\n",
    "            \n",
    "            # Filter out None values\n",
    "            thread_counts = [1, 2, 3, 4]\n",
    "            valid_data = [(t, time) for t, time in zip(thread_counts, times) if time is not None]\n",
    "            if valid_data:\n",
    "                threads, times = zip(*valid_data)\n",
    "                ax_tree.plot(threads, times, marker='o', linewidth=2, label=f'Depth {depth}')\n",
    "        \n",
    "        ax_tree.set_xlabel('Number of Threads')\n",
    "        ax_tree.set_ylabel('Training Time (ms)')\n",
    "        ax_tree.set_title(f'Tree Training - {dataset.capitalize()}')\n",
    "        ax_tree.legend()\n",
    "        ax_tree.grid(True, alpha=0.3)\n",
    "        ax_tree.set_yscale('log')\n",
    "        \n",
    "        # CV scaling\n",
    "        ax_cv = axes[1, i]\n",
    "        for depth in depths_to_analyze:\n",
    "            times = []\n",
    "            for threads in [1, 2, 3, 4]:\n",
    "                data = parallel_cv_df[(parallel_cv_df['dataset'] == dataset) & \n",
    "                                    (parallel_cv_df['max_depth'] == depth) & \n",
    "                                    (parallel_cv_df['threads'] == threads)]\n",
    "                if not data.empty:\n",
    "                    times.append(data['cv_time_ms'].iloc[0])\n",
    "                else:\n",
    "                    times.append(None)\n",
    "            \n",
    "            # Filter out None values\n",
    "            thread_counts = [1, 2, 3, 4]\n",
    "            valid_data = [(t, time) for t, time in zip(thread_counts, times) if time is not None]\n",
    "            if valid_data:\n",
    "                threads, times = zip(*valid_data)\n",
    "                ax_cv.plot(threads, times, marker='s', linewidth=2, label=f'Depth {depth}')\n",
    "        \n",
    "        ax_cv.set_xlabel('Number of Threads')\n",
    "        ax_cv.set_ylabel('CV Time (ms)')\n",
    "        ax_cv.set_title(f'Cross-Validation - {dataset.capitalize()}')\n",
    "        ax_cv.legend()\n",
    "        ax_cv.grid(True, alpha=0.3)\n",
    "        ax_cv.set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('thread_scaling_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Execute thread scaling analysis\n",
    "plot_thread_scaling()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a617a4c",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Performance Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c362da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "def calculate_performance_stats():\n",
    "    \"\"\"Calculate and display performance summary statistics\"\"\"\n",
    "    print(\"=== PERFORMANCE SUMMARY STATISTICS ===\\n\")\n",
    "    \n",
    "    for dataset in ['cancer', 'hmeq']:\n",
    "        print(f\"📊 {dataset.upper()} DATASET\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Tree performance stats\n",
    "        serial_tree = serial_tree_df[serial_tree_df['dataset'] == dataset]\n",
    "        parallel_tree_4 = parallel_tree_df[(parallel_tree_df['dataset'] == dataset) & \n",
    "                                         (parallel_tree_df['threads'] == 4)]\n",
    "        \n",
    "        avg_tree_speedup = (serial_tree['train_time_ms'].mean() / \n",
    "                           parallel_tree_4['train_time_ms'].mean())\n",
    "        \n",
    "        print(f\"🌳 Tree Training:\")\n",
    "        print(f\"   Average serial time: {serial_tree['train_time_ms'].mean():.2f} ms\")\n",
    "        print(f\"   Average parallel time (4 threads): {parallel_tree_4['train_time_ms'].mean():.2f} ms\")\n",
    "        print(f\"   Average speedup: {avg_tree_speedup:.2f}x\")\n",
    "        \n",
    "        # CV performance stats\n",
    "        serial_cv = serial_cv_df[serial_cv_df['dataset'] == dataset]\n",
    "        parallel_cv_4 = parallel_cv_df[(parallel_cv_df['dataset'] == dataset) & \n",
    "                                     (parallel_cv_df['threads'] == 4)]\n",
    "        \n",
    "        avg_cv_speedup = (serial_cv['cv_time_ms'].mean() / \n",
    "                         parallel_cv_4['cv_time_ms'].mean())\n",
    "        \n",
    "        print(f\"🔄 Cross-Validation:\")\n",
    "        print(f\"   Average serial time: {serial_cv['cv_time_ms'].mean():.2f} ms\")\n",
    "        print(f\"   Average parallel time (4 threads): {parallel_cv_4['cv_time_ms'].mean():.2f} ms\")\n",
    "        print(f\"   Average speedup: {avg_cv_speedup:.2f}x\")\n",
    "        print()\n",
    "\n",
    "# Calculate and display summary statistics\n",
    "calculate_performance_stats()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4574dace",
   "metadata": {},
   "source": [
    "## 6. Best Performance Configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef755cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_configurations():\n",
    "    \"\"\"Find the best performing configurations\"\"\"\n",
    "    print(\"=== BEST PERFORMANCE CONFIGURATIONS ===\\n\")\n",
    "    \n",
    "    for dataset in ['cancer', 'hmeq']:\n",
    "        print(f\"🏆 {dataset.upper()} DATASET - OPTIMAL CONFIGURATIONS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Find best tree training configuration\n",
    "        dataset_tree_data = parallel_tree_df[parallel_tree_df['dataset'] == dataset]\n",
    "        best_tree_config = dataset_tree_data.loc[dataset_tree_data['train_time_ms'].idxmin()]\n",
    "        \n",
    "        print(f\"🌳 Fastest Tree Training:\")\n",
    "        print(f\"   Depth: {best_tree_config['max_depth']}\")\n",
    "        print(f\"   Threads: {best_tree_config['threads']}\")\n",
    "        print(f\"   Time: {best_tree_config['train_time_ms']:.2f} ms\")\n",
    "        print(f\"   Accuracy: {best_tree_config['test_accuracy']:.3f}\")\n",
    "        \n",
    "        # Find best CV configuration\n",
    "        dataset_cv_data = parallel_cv_df[parallel_cv_df['dataset'] == dataset]\n",
    "        best_cv_config = dataset_cv_data.loc[dataset_cv_data['cv_time_ms'].idxmin()]\n",
    "        \n",
    "        print(f\"🔄 Fastest Cross-Validation:\")\n",
    "        print(f\"   Depth: {best_cv_config['max_depth']}\")\n",
    "        print(f\"   Threads: {best_cv_config['threads']}\")\n",
    "        print(f\"   Time: {best_cv_config['cv_time_ms']:.2f} ms\")\n",
    "        print(f\"   CV Accuracy: {best_cv_config['mean_cv_accuracy']:.3f}\")\n",
    "        print()\n",
    "\n",
    "# Find and display best configurations\n",
    "find_best_configurations()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
